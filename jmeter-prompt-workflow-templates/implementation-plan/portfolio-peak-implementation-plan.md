# Portfolio Peak Performance Test - JMeter Implementation Plan

**Version:** 1.0
**Date:** 2026-01-14
**Test Plan Reference:** `portfolio-processing-performance-test-plan.md`
**Target Output:** `portfolio-peak-test-no-groovy.jmx`
**Based On:** `portfolio-baseline-test-no-groovy.jmx` (Tested: 2026-01-13, Achieved: 72.6 TPS)

---

## 1. Executive Summary

This implementation plan defines the exact approach, components, and configurations required to implement the **Portfolio Peak Performance Test** in Apache JMeter. The peak test simulates 20% growth over baseline load with **60.42 TPS** distributed across 6 payload sizes over a 30-minute test window (2min ramp-up ‚Üí 28min steady-state).

### Prerequisites Validated
- ‚úÖ **Authentication:** None required (pure API load test)
- ‚úÖ **Test Data:** All 6 JSON files present and validated in `testdata/`
- ‚úÖ **Monitoring:** JMeter HTML Dashboard Report + Google Cloud Console Metrics
- ‚úÖ **Scope:** Peak test (60.42 TPS target, +20% above baseline)
- ‚úÖ **Baseline Results:** Completed successfully (72.6 TPS achieved, 0.51% error rate)

### Java Compatibility Approach
- **Version Used:** No-Groovy version (Java 24+ compatible)
- **JSON Loading:** `__FileToString()` built-in function (no JSR223 PreProcessor)
- **Plugins Required:** ‚ùå **NONE** (uses standard JMeter components only)

**Rationale:** The no-groovy version eliminates Java version dependencies and plugin requirements, making the test plan portable and compatible with Java 8 through Java 24+. This approach sacrifices JSON caching for maximum compatibility.

---

## 2. Test Plan Architecture

### 2.1 Component Hierarchy

```
Test Plan: Portfolio Processing - Peak Test (No Groovy - Java 24 Compatible)
‚îÇ
‚îú‚îÄ‚îÄ User Defined Variables (UDV-TestConfig)
‚îÇ
‚îú‚îÄ‚îÄ HTTP Header Manager (HTTP-Headers-JSON)
‚îÇ
‚îú‚îÄ‚îÄ Thread Group 1: TG-Small-3-Peak
‚îÇ   ‚îú‚îÄ‚îÄ Constant Timer (Timer-ThinkTime-0.5s)
‚îÇ   ‚îú‚îÄ‚îÄ Constant Throughput Timer (CTT-Small-3)
‚îÇ   ‚îú‚îÄ‚îÄ HTTP Request (POST-PortfolioProcessing)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Body Data: ${__FileToString(${TESTDATA_DIR}/holdings_3_411929.json,,)}
‚îÇ   ‚îú‚îÄ‚îÄ Response Assertion (Assert-HTTP200)
‚îÇ   ‚îî‚îÄ‚îÄ Duration Assertion (Assert-ResponseTime-Small3)
‚îÇ
‚îú‚îÄ‚îÄ Thread Group 2: TG-Small-10-Peak
‚îÇ   ‚îú‚îÄ‚îÄ Constant Timer (Timer-ThinkTime-0.5s)
‚îÇ   ‚îú‚îÄ‚îÄ Constant Throughput Timer (CTT-Small-10)
‚îÇ   ‚îú‚îÄ‚îÄ HTTP Request (POST-PortfolioProcessing)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Body Data: ${__FileToString(${TESTDATA_DIR}/holdings_10_109757.json,,)}
‚îÇ   ‚îú‚îÄ‚îÄ Response Assertion (Assert-HTTP200)
‚îÇ   ‚îî‚îÄ‚îÄ Duration Assertion (Assert-ResponseTime-Small10)
‚îÇ
‚îú‚îÄ‚îÄ Thread Group 3: TG-Medium-67-Peak
‚îÇ   ‚îú‚îÄ‚îÄ Constant Timer (Timer-ThinkTime-0.5s)
‚îÇ   ‚îú‚îÄ‚îÄ Constant Throughput Timer (CTT-Medium-67)
‚îÇ   ‚îú‚îÄ‚îÄ HTTP Request (POST-PortfolioProcessing)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Body Data: ${__FileToString(${TESTDATA_DIR}/holdings_67_981936.json,,)}
‚îÇ   ‚îú‚îÄ‚îÄ Response Assertion (Assert-HTTP200)
‚îÇ   ‚îî‚îÄ‚îÄ Duration Assertion (Assert-ResponseTime-Medium67)
‚îÇ
‚îú‚îÄ‚îÄ Thread Group 4: TG-Large-105-Peak
‚îÇ   ‚îú‚îÄ‚îÄ Constant Timer (Timer-ThinkTime-0.5s)
‚îÇ   ‚îú‚îÄ‚îÄ Constant Throughput Timer (CTT-Large-105)
‚îÇ   ‚îú‚îÄ‚îÄ HTTP Request (POST-PortfolioProcessing)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Body Data: ${__FileToString(${TESTDATA_DIR}/holdings_105_615062.json,,)}
‚îÇ   ‚îú‚îÄ‚îÄ Response Assertion (Assert-HTTP200)
‚îÇ   ‚îî‚îÄ‚îÄ Duration Assertion (Assert-ResponseTime-Large105)
‚îÇ
‚îú‚îÄ‚îÄ Thread Group 5: TG-XLarge-245-Peak
‚îÇ   ‚îú‚îÄ‚îÄ Constant Timer (Timer-ThinkTime-0.5s)
‚îÇ   ‚îú‚îÄ‚îÄ Constant Throughput Timer (CTT-XLarge-245)
‚îÇ   ‚îú‚îÄ‚îÄ HTTP Request (POST-PortfolioProcessing)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Body Data: ${__FileToString(${TESTDATA_DIR}/holdings_245_358040.json,,)}
‚îÇ   ‚îú‚îÄ‚îÄ Response Assertion (Assert-HTTP200)
‚îÇ   ‚îî‚îÄ‚îÄ Duration Assertion (Assert-ResponseTime-XLarge245)
‚îÇ
‚îú‚îÄ‚îÄ Thread Group 6: TG-XXLarge-580-Peak
‚îÇ   ‚îú‚îÄ‚îÄ Constant Timer (Timer-ThinkTime-0.5s)
‚îÇ   ‚îú‚îÄ‚îÄ Constant Throughput Timer (CTT-XXLarge-580)
‚îÇ   ‚îú‚îÄ‚îÄ HTTP Request (POST-PortfolioProcessing)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Body Data: ${__FileToString(${TESTDATA_DIR}/holdings_580_491573.json,,)}
‚îÇ   ‚îú‚îÄ‚îÄ Response Assertion (Assert-HTTP200)
‚îÇ   ‚îî‚îÄ‚îÄ Duration Assertion (Assert-ResponseTime-XXLarge580)
‚îÇ
‚îú‚îÄ‚îÄ View Results Tree (Listener-Debug) [ENABLED for GUI testing]
‚îî‚îÄ‚îÄ Aggregate Report (Listener-Summary)
```

**Key Differences from Baseline:**
- ‚ùå **NO JSR223 PreProcessors** (no Groovy scripts)
- ‚úÖ **__FileToString()** used directly in HTTP Request body
- ‚úÖ **Standard Thread Groups** (not Ultimate Thread Groups)
- ‚úÖ **Constant Throughput Timers** (not Precise Throughput Timers)
- ‚¨ÜÔ∏è **53 total threads** (vs 44 in baseline)
- ‚¨ÜÔ∏è **60.42 TPS target** (vs 50.35 in baseline)

---

## 3. Detailed Component Configurations

### 3.1 User Defined Variables (UDV-TestConfig)

**Element Type:** `User Defined Variables`
**Scope:** Test Plan Level (Global)
**Purpose:** Centralize configuration parameters for easy modification

| Variable Name | Default Value | Description | Command-Line Override |
|---------------|---------------|-------------|----------------------|
| `TESTDATA_DIR` | `/Users/samisabir-idrissi/dev/personal/prompt-templates-demo-share/jmeter-prompt-workflow-templates/testdata` | Absolute path to JSON test data directory | `-Jtestdata_dir=/path/to/testdata` |
| `TARGET_HOST` | `process-portfolio-4bzwg5efpa-uc.a.run.app` | Google Cloud Run hostname | `-Jtarget_host=your-api.example.com` |
| `TARGET_PORT` | `443` | HTTPS port | `-Jtarget_port=443` |
| `TARGET_PROTOCOL` | `https` | Protocol (http/https) | `-Jtarget_protocol=https` |
| `TARGET_PATH` | `/` | API endpoint path | `-Jtarget_path=/api/v1/process` |

**Implementation Pattern:**
```xml
<stringProp name="Argument.value">${__P(testdata_dir,/Users/.../testdata)}</stringProp>
```

**Usage Example:**
```bash
jmeter -n -t portfolio-peak-test-no-groovy.jmx \
       -Jtarget_host=prod-api.example.com \
       -Jtarget_port=443 \
       -Jtarget_protocol=https \
       -l results/peak-results.jtl
```

**Critical Note:** `TESTDATA_DIR` MUST be an absolute path. Relative paths may fail depending on JMeter's working directory.

---

### 3.2 HTTP Header Manager (HTTP-Headers-JSON)

**Element Type:** `HTTP Header Manager`
**Scope:** Test Plan Level (applies to all HTTP requests)
**Purpose:** Set required HTTP headers for JSON POST requests

| Header Name | Value | Rationale |
|-------------|-------|-----------|
| `Content-Type` | `application/json` | Required for JSON payloads |
| `Accept` | `application/json` | Indicates expected response format |

**XML Configuration:**
```xml
<HeaderManager guiclass="HeaderPanel" testclass="HeaderManager" testname="HTTP-Headers-JSON">
  <collectionProp name="HeaderManager.headers">
    <elementProp name="" elementType="Header">
      <stringProp name="Header.name">Content-Type</stringProp>
      <stringProp name="Header.value">application/json</stringProp>
    </elementProp>
    <elementProp name="" elementType="Header">
      <stringProp name="Header.name">Accept</stringProp>
      <stringProp name="Header.value">application/json</stringProp>
    </elementProp>
  </collectionProp>
</HeaderManager>
```

---

### 3.3 Thread Groups Configuration

Each payload size requires its own **Standard Thread Group** with identical structure but different parameters.

#### 3.3.1 Standard Thread Group - General Settings

**Element Type:** `ThreadGroup` (built-in JMeter component)
**Action After Sampler Error:** Continue
**Loop Count:** Forever (infinite loop, controlled by duration)
**Scheduler:** ‚úÖ Enabled

#### 3.3.2 Thread Group Schedule Parameters

| Parameter | Value | Description |
|-----------|-------|-------------|
| **Number of Threads** | Varies by payload | Total virtual users for this thread group |
| **Ramp-Up Period** | `120` seconds | 2 minutes to start all threads gradually |
| **Duration** | `1800` seconds | 30 minutes total test duration |
| **Startup Delay** | `0` seconds | All thread groups start simultaneously |

**Total Test Timeline:**
```
0:00 - 2:00   (120s)  ‚Üí RAMP-UP: Threads starting gradually
2:00 - 30:00  (1680s) ‚Üí STEADY-STATE: All threads running at full load
30:00                 ‚Üí ABRUPT STOP: All threads terminate immediately
```

**Note:** Unlike Ultimate Thread Group (plugin version), Standard Thread Groups do NOT have gradual ramp-down. Threads stop abruptly at 30:00.

#### 3.3.3 Thread Group Specific Parameters (Peak Test)

| Thread Group Name | Threads | TPS Target | RPM Target | Think Time | Response Time SLA | JSON File | Expected Samples (30 min) |
|-------------------|---------|------------|------------|------------|-------------------|-----------|---------------------------|
| `TG-Small-3-Peak` | **14** | 21.15 | 1269.0 | 0.5s | 300ms | `holdings_3_411929.json` | 38,070 |
| `TG-Small-10-Peak` | **14** | 21.15 | 1269.0 | 0.5s | 400ms | `holdings_10_109757.json` | 38,070 |
| `TG-Medium-67-Peak` | **13** | 12.08 | 724.8 | 0.5s | 800ms | `holdings_67_981936.json` | 21,744 |
| `TG-Large-105-Peak` | **6** | 4.23 | 253.8 | 0.5s | 1200ms | `holdings_105_615062.json` | 7,614 |
| `TG-XLarge-245-Peak` | **3** | 1.21 | 72.6 | 0.5s | 2500ms | `holdings_245_358040.json` | 2,178 |
| `TG-XXLarge-580-Peak` | **3** | 0.60 | 36.0 | 0.5s | 5000ms | `holdings_580_491573.json` | 1,080 |
| **TOTAL** | **53** | **60.42** | **3625.2** | - | - | - | **108,756** |

**Source:** Test Plan Section 5.1, Lines 149-159

**Comparison with Baseline:**

| Thread Group | Baseline Threads | Peak Threads | Change | Baseline TPS | Peak TPS | Change |
|--------------|------------------|--------------|--------|--------------|----------|--------|
| TG-Small-3 | 11 | 14 | +3 (+27%) | 17.62 | 21.15 | +3.53 (+20%) |
| TG-Small-10 | 12 | 14 | +2 (+17%) | 17.62 | 21.15 | +3.53 (+20%) |
| TG-Medium-67 | 11 | 13 | +2 (+18%) | 10.07 | 12.08 | +2.01 (+20%) |
| TG-Large-105 | 5 | 6 | +1 (+20%) | 3.52 | 4.23 | +0.71 (+20%) |
| TG-XLarge-245 | 3 | 3 | 0 (0%) | 1.01 | 1.21 | +0.20 (+20%) |
| TG-XXLarge-580 | 2 | 3 | +1 (+50%) | 0.50 | 0.60 | +0.10 (+20%) |

---

### 3.4 JSON Data Loading Strategy (No-Groovy Approach)

**Approach:** Direct file reading via `__FileToString()` JMeter function
**Location:** HTTP Request ‚Üí Body Data field
**Performance Trade-off:** Reads file on **every iteration** (no caching)

#### 3.4.1 __FileToString() Function Syntax

**Format:**
```
${__FileToString(${TESTDATA_DIR}/holdings_3_411929.json,,)}
```

**Parameters:**
1. **File path**: `${TESTDATA_DIR}/holdings_3_411929.json` (variable + filename)
2. **Encoding**: `,` (empty, uses default UTF-8)
3. **Variable name**: `,` (empty, not storing in variable)

**How It Works:**
1. JMeter evaluates `${TESTDATA_DIR}` ‚Üí `/Users/.../testdata`
2. Constructs full path: `/Users/.../testdata/holdings_3_411929.json`
3. Reads entire file contents as string
4. Returns JSON string directly to HTTP Request body
5. **Repeats for every iteration** (no caching mechanism)

#### 3.4.2 Performance Implications

| Aspect | Groovy Version (Baseline) | __FileToString() Version (Peak) |
|--------|---------------------------|----------------------------------|
| **File Reads** | 44 total (once per thread) | ~108,756 (every iteration) |
| **Memory Usage** | Cached in JMeter variables (~1.3MB total) | No caching, file system cache used |
| **CPU Overhead** | Groovy compilation (first iteration only) | Native JMeter function (minimal) |
| **I/O Overhead** | Negligible after first read | File I/O every iteration (~0.01ms per read) |
| **Java Compatibility** | Java 8-19 only | Java 8-24+ (any version) |

**Expected Impact:** With file sizes 411KB-580KB and modern SSDs, the I/O overhead is **<1% of total response time** (baseline average: 47ms, file read: ~0.5-1ms). This trade-off is acceptable for Java 24+ compatibility.

#### 3.4.3 Per-Thread-Group JSON File Mapping

| Thread Group | JSON File | File Size | __FileToString() Expression |
|--------------|-----------|-----------|----------------------------|
| TG-Small-3-Peak | `holdings_3_411929.json` | 411 KB | `${__FileToString(${TESTDATA_DIR}/holdings_3_411929.json,,)}` |
| TG-Small-10-Peak | `holdings_10_109757.json` | 109 KB | `${__FileToString(${TESTDATA_DIR}/holdings_10_109757.json,,)}` |
| TG-Medium-67-Peak | `holdings_67_981936.json` | 981 KB | `${__FileToString(${TESTDATA_DIR}/holdings_67_981936.json,,)}` |
| TG-Large-105-Peak | `holdings_105_615062.json` | 615 KB | `${__FileToString(${TESTDATA_DIR}/holdings_105_615062.json,,)}` |
| TG-XLarge-245-Peak | `holdings_245_358040.json` | 358 KB | `${__FileToString(${TESTDATA_DIR}/holdings_245_358040.json,,)}` |
| TG-XXLarge-580-Peak | `holdings_580_491573.json` | 491 KB | `${__FileToString(${TESTDATA_DIR}/holdings_580_491573.json,,)}` |

---

### 3.5 Constant Timer Configuration

**Element Type:** `Constant Timer`
**Scope:** Each Thread Group (6 total, identical configuration)
**Purpose:** Simulate think time between requests

| Parameter | Value | Rationale |
|-----------|-------|-----------|
| **Thread Delay (ms)** | `500` | 0.5 second think time between iterations |
| **Timer Name** | `Timer-ThinkTime-0.5s` | Descriptive naming convention |

**Implementation:**
```xml
<ConstantTimer guiclass="ConstantTimerGui" testclass="ConstantTimer" testname="Timer-ThinkTime-0.5s">
  <stringProp name="ConstantTimer.delay">500</stringProp>
</ConstantTimer>
```

**Rationale:** Uses fixed 500ms delay (not random) to maintain predictable, deterministic load patterns consistent with rate-based testing approach.

---

### 3.6 Constant Throughput Timer Configuration

**Element Type:** `Constant Throughput Timer`
**Scope:** Each Thread Group (6 total, unique TPS per group)
**Purpose:** Enforce TPS targets for rate-based load control

#### 3.6.1 Configuration Parameters

| Parameter | Description | Implementation |
|-----------|-------------|----------------|
| **Target throughput** | Requests per **minute** | TPS √ó 60 (e.g., 21.15 TPS = 1269.0 RPM) |
| **Calculate Throughput based on** | Distribution mode | `This thread only` (mode 0) |
| **Timer Name** | Descriptive identifier | `CTT-[PayloadSize]` |

**Important:** Constant Throughput Timer requires **requests per minute**, not TPS. Formula: `RPM = TPS √ó 60`

#### 3.6.2 Per-Thread-Group Configuration (Peak Test)

| Thread Group | Timer Name | TPS Target | RPM Target | calcMode | Expected Behavior |
|--------------|------------|------------|------------|----------|-------------------|
| TG-Small-3-Peak | `CTT-Small-3` | 21.15 | **1269.0** | 0 | 21.15 req/sec sustained |
| TG-Small-10-Peak | `CTT-Small-10` | 21.15 | **1269.0** | 0 | 21.15 req/sec sustained |
| TG-Medium-67-Peak | `CTT-Medium-67` | 12.08 | **724.8** | 0 | 12.08 req/sec sustained |
| TG-Large-105-Peak | `CTT-Large-105` | 4.23 | **253.8** | 0 | 4.23 req/sec sustained |
| TG-XLarge-245-Peak | `CTT-XLarge-245` | 1.21 | **72.6** | 0 | 1.21 req/sec sustained |
| TG-XXLarge-580-Peak | `CTT-XXLarge-580` | 0.60 | **36.0** | 0 | 0.60 req/sec sustained |

**XML Example (TG-Small-3):**
```xml
<ConstantThroughputTimer guiclass="TestBeanGUI" testclass="ConstantThroughputTimer" testname="CTT-Small-3">
  <intProp name="calcMode">0</intProp>
  <doubleProp>
    <name>throughput</name>
    <value>1269.0</value>
  </doubleProp>
</ConstantThroughputTimer>
```

**calcMode Values:**
- `0` = This thread only (recommended for independent thread groups)
- `1` = All active threads
- `2` = All active threads in current thread group
- `3` = All active threads (shared)
- `4` = All active threads in current thread group (shared)

#### 3.6.3 Accuracy Characteristics

**Constant Throughput Timer vs Precise Throughput Timer:**

| Feature | Constant Throughput Timer | Precise Throughput Timer (Plugin) |
|---------|---------------------------|-----------------------------------|
| **TPS Accuracy** | ¬±5-10% | ¬±1% |
| **Warm-up Period** | ~30-60 seconds | Immediate (from second 1) |
| **Stability** | Good after warm-up | Excellent throughout |
| **Plugins Required** | ‚ùå No | ‚úÖ Yes |
| **Use Case** | General load testing | SLA validation, production-grade |

**For Peak Test:** Constant Throughput Timer is acceptable because:
1. ‚úÖ Baseline test (with CTT) achieved 72.6 TPS (44% above target)
2. ‚úÖ Error rate stayed low (0.51%) even with higher-than-expected TPS
3. ‚úÖ No plugin dependencies = easier deployment and compatibility
4. ‚úÖ 30-minute test duration allows sufficient warm-up period

---

### 3.7 HTTP Request Configuration

**Element Type:** `HTTPSamplerProxy` (HTTP Request)
**Scope:** Each Thread Group (6 total, identical configuration except Body Data)
**Purpose:** Send POST request with JSON payload to target API

#### 3.7.1 HTTP Request Parameters

| Field | Value | Source |
|-------|-------|--------|
| **Name** | `POST-PortfolioProcessing` | Descriptive name |
| **Protocol** | `${TARGET_PROTOCOL}` | From UDV (default: `https`) |
| **Server Name or IP** | `${TARGET_HOST}` | From UDV (default: `process-portfolio-4bzwg5efpa-uc.a.run.app`) |
| **Port Number** | `${TARGET_PORT}` | From UDV (default: `443`) |
| **Method** | `POST` | Fixed |
| **Path** | `${TARGET_PATH}` | From UDV (default: `/`) |
| **Content Encoding** | `UTF-8` | Standard |
| **Body Data (Raw)** | `${__FileToString(...)}` | Loaded dynamically per thread group |
| **Use KeepAlive** | ‚úÖ Enabled | Connection reuse for performance |
| **Follow Redirects** | ‚ùå Disabled | Direct API call |
| **Use multipart/form-data** | ‚ùå Disabled | JSON body, not form data |

#### 3.7.2 Body Data Configuration (Per Thread Group)

**Body Data Type:** `Raw` (not parameters)
**Content:** JMeter function call to read JSON file

**Example (TG-Small-3-Peak):**
```xml
<HTTPSamplerProxy guiclass="HttpTestSampleGui" testclass="HTTPSamplerProxy" testname="POST-PortfolioProcessing">
  <boolProp name="HTTPSampler.postBodyRaw">true</boolProp>
  <elementProp name="HTTPsampler.Arguments" elementType="Arguments">
    <collectionProp name="Arguments.arguments">
      <elementProp name="" elementType="HTTPArgument">
        <boolProp name="HTTPArgument.always_encode">false</boolProp>
        <stringProp name="Argument.value">${__FileToString(${TESTDATA_DIR}/holdings_3_411929.json,,)}</stringProp>
      </elementProp>
    </collectionProp>
  </elementProp>
  <stringProp name="HTTPSampler.domain">${TARGET_HOST}</stringProp>
  <stringProp name="HTTPSampler.port">${TARGET_PORT}</stringProp>
  <stringProp name="HTTPSampler.protocol">${TARGET_PROTOCOL}</stringProp>
  <stringProp name="HTTPSampler.method">POST</stringProp>
  <stringProp name="HTTPSampler.path">${TARGET_PATH}</stringProp>
  <boolProp name="HTTPSampler.use_keepalive">true</boolProp>
</HTTPSamplerProxy>
```

**Actual HTTP Request Structure:**
```http
POST / HTTP/1.1
Host: process-portfolio-4bzwg5efpa-uc.a.run.app:443
Content-Type: application/json
Accept: application/json
User-Agent: Apache-HttpClient/4.5.13 (Java/24.0.1)

[JSON content from holdings_3_411929.json loaded via __FileToString()]
```

---

### 3.8 Response Assertion Configuration

**Element Type:** `ResponseAssertion`
**Scope:** Each Thread Group (6 total, identical configuration)
**Purpose:** Validate HTTP 200 success response

| Parameter | Value |
|-----------|-------|
| **Name** | `Assert-HTTP200` |
| **Apply to** | Main sample only |
| **Response Field** | Response Code |
| **Pattern Matching Rules** | Equals |
| **Patterns to Test** | `200` |

**XML Configuration:**
```xml
<ResponseAssertion guiclass="AssertionGui" testclass="ResponseAssertion" testname="Assert-HTTP200">
  <collectionProp name="Asserion.test_strings">
    <stringProp name="49586">200</stringProp>
  </collectionProp>
  <stringProp name="Assertion.test_field">Assertion.response_code</stringProp>
  <boolProp name="Assertion.assume_success">false</boolProp>
  <intProp name="Assertion.test_type">8</intProp>
</ResponseAssertion>
```

**Failure Behavior:** If response code ‚â† 200, the sample is marked as **FAILED** in results. Test execution continues.

**Validation Logic:**
- ‚úÖ HTTP 200 ‚Üí Sample marked SUCCESS
- ‚ùå HTTP 4xx/5xx ‚Üí Sample marked FAILED
- ‚ùå Network timeout ‚Üí Sample marked FAILED
- ‚ùå Connection refused ‚Üí Sample marked FAILED

---

### 3.9 Duration Assertion Configuration

**Element Type:** `DurationAssertion`
**Scope:** Each Thread Group (6 instances with payload-specific SLAs)
**Purpose:** Enforce response time SLAs per payload size

#### 3.9.1 Per-Thread-Group SLA Configuration

| Thread Group | Assertion Name | SLA Threshold (ms) | Payload Size | Expected Avg Response Time |
|--------------|----------------|-------------------|--------------|----------------------------|
| TG-Small-3-Peak | `Assert-ResponseTime-Small3` | **300** | 3 holdings | ~120ms (baseline: 47ms) |
| TG-Small-10-Peak | `Assert-ResponseTime-Small10` | **400** | 10 holdings | ~150ms (baseline: 47ms) |
| TG-Medium-67-Peak | `Assert-ResponseTime-Medium67` | **800** | 67 holdings | ~500ms (baseline: 47ms) |
| TG-Large-105-Peak | `Assert-ResponseTime-Large105` | **1200** | 105 holdings | ~750ms (baseline: 47ms) |
| TG-XLarge-245-Peak | `Assert-ResponseTime-XLarge245` | **2500** | 245 holdings | ~1800ms (baseline: 47ms) |
| TG-XXLarge-580-Peak | `Assert-ResponseTime-XXLarge580` | **5000** | 580 holdings | ~3500ms (baseline: 47ms) |

**Note:** Baseline test achieved **47ms average** across all payloads, well below all SLA thresholds. Peak test expected to achieve similar performance (50-60ms average).

**XML Example (TG-Small-3):**
```xml
<DurationAssertion guiclass="DurationAssertionGui" testclass="DurationAssertion" testname="Assert-ResponseTime-Small3">
  <stringProp name="DurationAssertion.duration">300</stringProp>
</DurationAssertion>
```

**Failure Behavior:**
- ‚úÖ Response time ‚â§ SLA ‚Üí No error
- ‚ùå Response time > SLA ‚Üí Sample marked FAILED (but test continues)
- üìä Results show: "X% samples exceeded SLA"

**Expected SLA Compliance (Based on Baseline):**
- **Target:** ‚â•95% of samples within SLA
- **Baseline Actual:** >99% of samples within SLA (47ms avg vs 300-5000ms SLAs)
- **Peak Expected:** >99% of samples within SLA (similar fast response times)

---

### 3.10 Listener Configuration

#### 3.10.1 View Results Tree (Listener-Debug)

**Element Type:** `ResultCollector` (View Results Tree)
**Scope:** Test Plan Level
**Purpose:** View live request/response data during GUI test execution
**Status:** ‚úÖ **ENABLED** (for GUI testing, disable for headless runs)

**Configuration:**
- **Display:** Request + Response + Response Headers
- **Save:** All data (for debugging)
- **Filename:** Empty (in-memory only)

**Usage:**
- Click "View Results Tree" in left panel during test
- Watch requests appear in real-time
- Click any sample to see:
  - Request body (JSON payload)
  - Response data
  - Response time
  - HTTP status code
  - Assertions results

**Performance Impact:** High memory usage with long-running tests. Disable for production runs by setting `enabled="false"` in XML.

#### 3.10.2 Aggregate Report (Listener-Summary)

**Element Type:** `ResultCollector` (Aggregate Report)
**Scope:** Test Plan Level
**Purpose:** Real-time summary statistics
**Status:** ‚úÖ Enabled

**Metrics Displayed:**
- # Samples
- Average response time
- Median, 90%, 95%, 99% Line
- Min/Max response time
- Error %
- Throughput (TPS)
- Received/Sent KB/sec

**Usage:**
- Monitor TPS stabilization (should reach ~60.42 TPS after 2-3 minutes)
- Watch error rate (should stay <1%)
- Check response time percentiles

---

## 4. Implementation Steps

### Step 1: Validate Prerequisites

**Action:** Verify all requirements before implementation

**Checklist:**
- [ ] JMeter 5.6+ installed (`jmeter --version`)
- [ ] Java 8+ installed (`java --version`) - **ANY VERSION including Java 24**
- [ ] Test data directory exists: `ls -la ../testdata/`
- [ ] All 6 JSON files present (411KB, 109KB, 981KB, 615KB, 358KB, 491KB)
- [ ] Target endpoint accessible: `curl -I https://process-portfolio-4bzwg5efpa-uc.a.run.app`
- [ ] Baseline test results available for comparison

**Commands:**
```bash
# Verify JMeter
jmeter --version

# Verify Java (any version works)
java --version

# Verify test data
ls -lh /Users/samisabir-idrissi/dev/personal/prompt-templates-demo-share/jmeter-prompt-workflow-templates/testdata/*.json

# Test API connectivity
curl -X POST https://process-portfolio-4bzwg5efpa-uc.a.run.app/ \
     -H "Content-Type: application/json" \
     -d @/Users/samisabir-idrissi/dev/personal/prompt-templates-demo-share/jmeter-prompt-workflow-templates/testdata/holdings_3_411929.json
```

---

### Step 2: Create Test Plan Container

**Action:** Open JMeter GUI and create new test plan

```bash
cd /Users/samisabir-idrissi/dev/personal/prompt-templates-demo-share/jmeter-prompt-workflow-templates/perf-test-plan
jmeter
```

1. Right-click **Test Plan** ‚Üí Rename to: `Portfolio Processing - Peak Test (No Groovy - Java 24 Compatible)`
2. Add comments in Test Plan:
```
Portfolio Processing Performance Test - Peak Scenario (60.42 TPS)
Test Duration: ~30 minutes (2min ramp-up, ~28min steady-state)
Total Virtual Users: 53 threads across 6 payload sizes
Expected Total Samples: ~108,750

NOTE: This version uses NO GROOVY SCRIPTS - Java 24+ compatible
- Uses JMeter built-in __FileToString() function to load JSON
- No JSR223 PreProcessor (avoids Groovy compilation errors)
- Compatible with any Java version
- Standard JMeter Thread Groups (no plugins required)
```
3. Save as: `portfolio-peak-test-no-groovy.jmx`

---

### Step 3: Configure User Defined Variables

**Action:** Add global configuration variables

1. Right-click **Test Plan** ‚Üí Add ‚Üí Config Element ‚Üí **User Defined Variables**
2. Add variables:

| Name | Value |
|------|-------|
| TESTDATA_DIR | `${__P(testdata_dir,/Users/samisabir-idrissi/dev/personal/prompt-templates-demo-share/jmeter-prompt-workflow-templates/testdata)}` |
| TARGET_HOST | `${__P(target_host,process-portfolio-4bzwg5efpa-uc.a.run.app)}` |
| TARGET_PORT | `${__P(target_port,443)}` |
| TARGET_PROTOCOL | `${__P(target_protocol,https)}` |
| TARGET_PATH | `/` |

3. Save test plan

---

### Step 4: Add HTTP Header Manager

**Action:** Configure JSON headers for all requests

1. Right-click **Test Plan** ‚Üí Add ‚Üí Config Element ‚Üí **HTTP Header Manager**
2. Rename to: `HTTP-Headers-JSON`
3. Add headers:
   - Name: `Content-Type`, Value: `application/json`
   - Name: `Accept`, Value: `application/json`
4. Save test plan

---

### Step 5: Create Thread Group Template (TG-Small-3-Peak)

**Action:** Create first thread group as template

1. Right-click **Test Plan** ‚Üí Add ‚Üí Threads (Users) ‚Üí **Thread Group**
2. Configure:
   - **Name:** `TG-Small-3-Peak`
   - **Comments:**
```
Small Portfolio (3 holdings) - 35% of peak load
Threads: 14 | TPS Target: 21.15 | SLA: 300ms | Expected Samples: ~38,070
JSON loaded via __FileToString() function (no Groovy)
```
   - **Number of Threads:** `14`
   - **Ramp-up period:** `120` (seconds)
   - **Loop Count:** Forever ‚òë
   - **Duration:** `1800` (seconds)
   - **Startup delay:** `0`
3. Save test plan

---

### Step 6: Add Constant Timer

**Action:** Add 0.5s think time to TG-Small-3-Peak

1. Right-click **TG-Small-3-Peak** ‚Üí Add ‚Üí Timer ‚Üí **Constant Timer**
2. Configure:
   - **Name:** `Timer-ThinkTime-0.5s`
   - **Thread Delay:** `500` (milliseconds)
   - **Comments:** `0.5 second think time between requests`
3. Save test plan

---

### Step 7: Add Constant Throughput Timer

**Action:** Configure TPS enforcement for TG-Small-3-Peak

1. Right-click **TG-Small-3-Peak** ‚Üí Add ‚Üí Timer ‚Üí **Constant Throughput Timer**
2. Configure:
   - **Name:** `CTT-Small-3`
   - **Target throughput (in samples per minute):** `1269.0`
   - **Calculate Throughput based on:** `this thread only`
   - **Comments:** `Target: 21.15 TPS = 1269.0 requests/minute (per thread group)`
3. Save test plan

**Calculation:** 21.15 TPS √ó 60 seconds = 1269.0 RPM

---

### Step 8: Add HTTP Request Sampler

**Action:** Configure POST request with JSON body loading

1. Right-click **TG-Small-3-Peak** ‚Üí Add ‚Üí Sampler ‚Üí **HTTP Request**
2. Configure:
   - **Name:** `POST-PortfolioProcessing`
   - **Protocol:** `${TARGET_PROTOCOL}`
   - **Server Name or IP:** `${TARGET_HOST}`
   - **Port Number:** `${TARGET_PORT}`
   - **Method:** `POST`
   - **Path:** `${TARGET_PATH}`
   - **Body Data (select "Body Data" tab):**
```
${__FileToString(${TESTDATA_DIR}/holdings_3_411929.json,,)}
```
   - **Content encoding:** `UTF-8`
   - ‚òë **Use KeepAlive**
3. Save test plan

**Critical:** Ensure "Body Data" tab is selected (not "Parameters"). Paste the `__FileToString()` expression in the text area.

---

### Step 9: Add Response Assertion

**Action:** Validate HTTP 200 response

1. Right-click **POST-PortfolioProcessing** ‚Üí Add ‚Üí Assertions ‚Üí **Response Assertion**
2. Configure:
   - **Name:** `Assert-HTTP200`
   - **Apply to:** Main sample only
   - **Response Field to Test:** Response Code
   - **Pattern Matching Rules:** Equals
   - **Patterns to Test:** Add `200`
   - **Comments:** `Validates HTTP 200 success response`
3. Save test plan

---

### Step 10: Add Duration Assertion

**Action:** Enforce SLA for response time

1. Right-click **POST-PortfolioProcessing** ‚Üí Add ‚Üí Assertions ‚Üí **Duration Assertion**
2. Configure:
   - **Name:** `Assert-ResponseTime-Small3`
   - **Duration in milliseconds:** `300`
   - **Comments:** `SLA enforcement: Response time must be ‚â§ 300ms`
3. Save test plan

---

### Step 11: Replicate Thread Groups (TG-Small-10 through TG-XXLarge-580)

**Action:** Create remaining 5 thread groups

**Method:** Copy/paste TG-Small-3-Peak and modify parameters

For each additional thread group:

**TG-Small-10-Peak:**
1. Copy TG-Small-3-Peak ‚Üí Paste
2. Update:
   - Threads: `14`
   - Comments: `Small Portfolio (10 holdings)... Expected Samples: ~38,070`
   - CTT: `1269.0` RPM
   - HTTP Request Body: `${__FileToString(${TESTDATA_DIR}/holdings_10_109757.json,,)}`
   - Duration Assertion: `400` ms
   - Assertion Name: `Assert-ResponseTime-Small10`

**TG-Medium-67-Peak:**
1. Copy TG-Small-3-Peak ‚Üí Paste
2. Update:
   - Threads: `13`
   - Comments: `Medium Portfolio (67 holdings)... Expected Samples: ~21,744`
   - CTT: `724.8` RPM
   - HTTP Request Body: `${__FileToString(${TESTDATA_DIR}/holdings_67_981936.json,,)}`
   - Duration Assertion: `800` ms
   - Assertion Name: `Assert-ResponseTime-Medium67`

**TG-Large-105-Peak:**
1. Copy TG-Small-3-Peak ‚Üí Paste
2. Update:
   - Threads: `6`
   - Comments: `Large Portfolio (105 holdings)... Expected Samples: ~7,614`
   - CTT: `253.8` RPM
   - HTTP Request Body: `${__FileToString(${TESTDATA_DIR}/holdings_105_615062.json,,)}`
   - Duration Assertion: `1200` ms
   - Assertion Name: `Assert-ResponseTime-Large105`

**TG-XLarge-245-Peak:**
1. Copy TG-Small-3-Peak ‚Üí Paste
2. Update:
   - Threads: `3`
   - Comments: `Extra-Large Portfolio (245 holdings)... Expected Samples: ~2,178`
   - CTT: `72.6` RPM
   - HTTP Request Body: `${__FileToString(${TESTDATA_DIR}/holdings_245_358040.json,,)}`
   - Duration Assertion: `2500` ms
   - Assertion Name: `Assert-ResponseTime-XLarge245`

**TG-XXLarge-580-Peak:**
1. Copy TG-Small-3-Peak ‚Üí Paste
2. Update:
   - Threads: `3`
   - Comments: `Extra-Extra-Large Portfolio (580 holdings)... Expected Samples: ~1,080`
   - CTT: `36.0` RPM
   - HTTP Request Body: `${__FileToString(${TESTDATA_DIR}/holdings_580_491573.json,,)}`
   - Duration Assertion: `5000` ms
   - Assertion Name: `Assert-ResponseTime-XXLarge580`

**Final Thread Group Summary:**

| Thread Group | Threads | RPM | JSON File | Duration Assertion |
|--------------|---------|-----|-----------|-------------------|
| TG-Small-3-Peak | 14 | 1269.0 | holdings_3_411929.json | 300ms |
| TG-Small-10-Peak | 14 | 1269.0 | holdings_10_109757.json | 400ms |
| TG-Medium-67-Peak | 13 | 724.8 | holdings_67_981936.json | 800ms |
| TG-Large-105-Peak | 6 | 253.8 | holdings_105_615062.json | 1200ms |
| TG-XLarge-245-Peak | 3 | 72.6 | holdings_245_358040.json | 2500ms |
| TG-XXLarge-580-Peak | 3 | 36.0 | holdings_580_491573.json | 5000ms |
| **TOTAL** | **53** | **3625.2** | - | - |

Save test plan after creating all thread groups.

---

### Step 12: Add View Results Tree Listener

**Action:** Enable live request viewing for debugging

1. Right-click **Test Plan** ‚Üí Add ‚Üí Listener ‚Üí **View Results Tree**
2. Configure:
   - **Name:** `View Results Tree`
   - **Filename:** Leave empty (in-memory)
   - **Log/Display:** All options checked
   - **Save:** All options checked
   - **Comments:** `View live request/response data - ENABLED for GUI testing`
3. Save test plan

**Note:** This listener is enabled for GUI testing. For headless runs, it will be automatically inactive.

---

### Step 13: Add Aggregate Report Listener

**Action:** Add real-time statistics summary

1. Right-click **Test Plan** ‚Üí Add ‚Üí Listener ‚Üí **Aggregate Report**
2. Configure:
   - **Name:** `Listener-Summary`
   - **Filename:** Leave empty (in-memory)
   - **Comments:** `Aggregate Report - Real-time summary statistics`
3. Save test plan

---

### Step 14: Final Validation in GUI

**Action:** Verify test plan structure and run quick validation

**Pre-Run Checks:**
1. **Thread Count Validation:**
   - Sum of all threads = 53 (14+14+13+6+3+3)
2. **TPS Validation:**
   - Sum of all RPM = 3625.2 ‚Üí 3625.2 √∑ 60 = 60.42 TPS ‚úì
3. **File Path Validation:**
   - Check User Defined Variables ‚Üí TESTDATA_DIR has absolute path
   - Verify all `__FileToString()` expressions reference correct filenames

**Quick Validation Run (5 minutes):**
1. Temporarily modify ALL thread groups:
   - Duration: `300` (5 minutes instead of 1800)
   - Ramp-up: `60` (1 minute instead of 120)
2. Click **Start** (green ‚ñ∂Ô∏è button)
3. Watch "Aggregate Report":
   - TPS should stabilize around 60-80 TPS after 1-2 minutes
   - Error rate should be near 0%
4. Click "View Results Tree":
   - Verify requests are green (success)
   - Check response times (should be <100ms)
   - Inspect one request: verify JSON body is present
5. Stop test after 5 minutes
6. **Revert changes:** Set Duration back to `1800`, Ramp-up back to `120`
7. Save final test plan

---

### Step 15: Save Final Test Plan

**Action:** Save complete test plan

```bash
File ‚Üí Save As ‚Üí portfolio-peak-test-no-groovy.jmx
```

**File Location:**
```
/Users/samisabir-idrissi/dev/personal/prompt-templates-demo-share/jmeter-prompt-workflow-templates/perf-test-plan/portfolio-peak-test-no-groovy.jmx
```

---

## 5. Command-Line Execution

### 5.1 Basic Execution (GUI Mode)

```bash
cd /Users/samisabir-idrissi/dev/personal/prompt-templates-demo-share/jmeter-prompt-workflow-templates/perf-test-plan

jmeter -t portfolio-peak-test-no-groovy.jmx
```

**Use For:**
- Initial validation
- Debugging issues
- Viewing live requests

---

### 5.2 Headless Execution (Production Mode)

```bash
cd /Users/samisabir-idrissi/dev/personal/prompt-templates-demo-share/jmeter-prompt-workflow-templates/perf-test-plan

jmeter -n -t portfolio-peak-test-no-groovy.jmx \
       -l results/peak-results-$(date +%Y%m%d-%H%M%S).jtl \
       -j logs/peak-jmeter-$(date +%Y%m%d-%H%M%S).log \
       -e -o reports/peak-report-$(date +%Y%m%d-%H%M%S)
```

**Flags Explained:**
- `-n`: Non-GUI mode (headless)
- `-t`: Test plan file
- `-l`: Results file (.jtl format)
- `-j`: JMeter log file
- `-e`: Generate HTML report after test
- `-o`: Output directory for HTML report

**Output:**
- Results: `results/peak-results-20260114-153045.jtl`
- Logs: `logs/peak-jmeter-20260114-153045.log`
- HTML Report: `reports/peak-report-20260114-153045/index.html`

---

### 5.3 Custom Endpoint Execution

```bash
jmeter -n -t portfolio-peak-test-no-groovy.jmx \
       -Jtarget_host=staging-api.example.com \
       -Jtarget_port=8080 \
       -Jtarget_protocol=http \
       -Jtarget_path=/api/v2/portfolio \
       -l results/peak-staging.jtl \
       -e -o reports/peak-staging
```

**Use Cases:**
- Testing staging environment
- Testing different API versions
- Local development testing

---

### 5.4 View HTML Report

```bash
# macOS
open reports/peak-report-*/index.html

# Linux
xdg-open reports/peak-report-*/index.html

# Windows
start reports/peak-report-*/index.html
```

---

## 6. Expected Results & Success Criteria

### 6.1 Performance Targets (Peak Test)

| Metric | Target | Acceptable Range | Source |
|--------|--------|------------------|--------|
| **Total Duration** | 30 minutes | Exactly 30:00 | Test configuration |
| **Total Samples** | 108,750 | 103,000 - 114,500 (¬±5%) | 60.42 TPS √ó 1800s |
| **Overall TPS** | 60.42 | 57.4 - 63.4 (¬±5%) | Test plan specification |
| **Error Rate** | ‚â§1% | 0-1% | SLA requirement |
| **HTTP 200 Rate** | ‚â•99% | 99-100% | Success criterion |

### 6.2 Expected Results Based on Baseline Test

**Baseline Test Results (2026-01-13):**
- Actual TPS: **72.6/sec** (44% above 50.35 target)
- Total Samples: **130,569** (44% above 90,612 target)
- Error Rate: **0.51%** (well below 1% threshold)
- Average Response Time: **47ms**
- P95 Response Time: **57ms**
- P99 Response Time: **282ms**

**Peak Test Projections:**

| Metric | Target | Expected (Based on Baseline) |
|--------|--------|------------------------------|
| **TPS** | 60.42 | **85-90** (similar 40-45% overage) |
| **Total Samples** | 108,750 | **155,000-160,000** |
| **Error Rate** | <1% | **~0.5-1%** (should stay low) |
| **Avg Response Time** | Varies | **50-60ms** (slightly higher under load) |
| **P95 Response Time** | <SLA | **60-70ms** (well below all SLAs) |
| **P99 Response Time** | <SLA | **300-400ms** (within most SLAs) |

**Key Insight:** Baseline test already exceeded peak load target (72.6 > 60.42 TPS), so peak test should pass easily with similar performance characteristics.

### 6.3 Per-Thread-Group Expected Samples

| Thread Group | Target TPS | Expected Samples (30 min) | Acceptable Range (¬±5%) |
|--------------|------------|---------------------------|------------------------|
| TG-Small-3-Peak | 21.15 | 38,070 | 36,167 - 39,974 |
| TG-Small-10-Peak | 21.15 | 38,070 | 36,167 - 39,974 |
| TG-Medium-67-Peak | 12.08 | 21,744 | 20,657 - 22,831 |
| TG-Large-105-Peak | 4.23 | 7,614 | 7,233 - 7,995 |
| TG-XLarge-245-Peak | 1.21 | 2,178 | 2,069 - 2,287 |
| TG-XXLarge-580-Peak | 0.60 | 1,080 | 1,026 - 1,134 |

### 6.4 Response Time SLA Compliance

| Payload Size | SLA Threshold | Expected P95 | Expected P99 | Expected Compliance |
|--------------|---------------|--------------|--------------|---------------------|
| Small-3 | 300ms | 50-60ms | 200-250ms | >99% |
| Small-10 | 400ms | 50-60ms | 200-250ms | >99% |
| Medium-67 | 800ms | 50-60ms | 200-300ms | >99% |
| Large-105 | 1200ms | 50-70ms | 300-400ms | >99% |
| XLarge-245 | 2500ms | 50-70ms | 300-500ms | >99% |
| XXLarge-580 | 5000ms | 50-100ms | 500-1000ms | >99% |

**Based On:** Baseline test achieved 47ms average with P99 of 282ms, well below all SLA thresholds.

---

## 7. Validation Checklist

### 7.1 Pre-Test Validation

**Before Running Test:**

- [ ] **JMeter Configuration:**
  - [ ] JMeter 5.6+ installed
  - [ ] Java 8+ installed (any version including Java 24)
  - [ ] Heap size adequate: `-Xms2g -Xmx4g` for 53 threads

- [ ] **Test Plan Structure:**
  - [ ] 6 Thread Groups created (TG-Small-3 through TG-XXLarge-580)
  - [ ] Total thread count = 53
  - [ ] Total RPM = 3625.2 (= 60.42 TPS)
  - [ ] All thread groups: Duration = 1800s, Ramp-up = 120s

- [ ] **Test Data:**
  - [ ] TESTDATA_DIR variable set to absolute path
  - [ ] All 6 JSON files present in testdata directory
  - [ ] JSON files are valid (not corrupted)
  - [ ] File sizes correct (411KB, 109KB, 981KB, 615KB, 358KB, 491KB)

- [ ] **Endpoint Configuration:**
  - [ ] TARGET_HOST = `process-portfolio-4bzwg5efpa-uc.a.run.app`
  - [ ] TARGET_PORT = `443`
  - [ ] TARGET_PROTOCOL = `https`
  - [ ] API endpoint accessible (curl test successful)

- [ ] **Component Configuration:**
  - [ ] HTTP Header Manager present (Content-Type: application/json)
  - [ ] Each thread group has: Constant Timer (500ms)
  - [ ] Each thread group has: Constant Throughput Timer (correct RPM)
  - [ ] Each thread group has: HTTP Request with `__FileToString()` body
  - [ ] Each thread group has: Response Assertion (HTTP 200)
  - [ ] Each thread group has: Duration Assertion (correct SLA)

- [ ] **Listeners:**
  - [ ] View Results Tree present (enabled for GUI testing)
  - [ ] Aggregate Report present

---

### 7.2 Post-Test Validation

**After Test Completes:**

**Results File Validation:**
- [ ] `.jtl` file created and not empty
- [ ] `.jtl` file size reasonable (>1MB for 30-minute test)
- [ ] JMeter log file created (`.log`)
- [ ] HTML report generated (`index.html` present)

**Performance Metrics Validation:**
- [ ] Total samples: 103,000 - 160,000 (expected: 108,750)
- [ ] Overall TPS: 57-90 (target: 60.42)
- [ ] Test duration: 30 minutes ¬±10 seconds
- [ ] Error rate: ‚â§1% (expected: ~0.5%)
- [ ] HTTP 200 rate: ‚â•99%

**Per-Thread-Group Validation:**
- [ ] TG-Small-3: ~38,070 samples, TPS ~21.15
- [ ] TG-Small-10: ~38,070 samples, TPS ~21.15
- [ ] TG-Medium-67: ~21,744 samples, TPS ~12.08
- [ ] TG-Large-105: ~7,614 samples, TPS ~4.23
- [ ] TG-XLarge-245: ~2,178 samples, TPS ~1.21
- [ ] TG-XXLarge-580: ~1,080 samples, TPS ~0.60

**Response Time Validation:**
- [ ] Average response time: 50-100ms (expected: similar to baseline 47ms)
- [ ] P95 response time: <100ms (well below SLAs)
- [ ] P99 response time: <500ms (well below SLAs)
- [ ] Max response time: <5000ms (within worst-case SLA)

**SLA Compliance:**
- [ ] Small-3: >95% samples <300ms
- [ ] Small-10: >95% samples <400ms
- [ ] Medium-67: >95% samples <800ms
- [ ] Large-105: >95% samples <1200ms
- [ ] XLarge-245: >95% samples <2500ms
- [ ] XXLarge-580: >95% samples <5000ms

**Google Cloud Metrics Validation:**
- [ ] CPU utilization <80% throughout test
- [ ] Memory utilization <80% throughout test
- [ ] Cloud Function instances scaled appropriately
- [ ] No rate limiting errors in logs
- [ ] No cold start issues (or minimal impact)

---

### 7.3 Comparison with Baseline Test

**Validate Peak vs Baseline:**

| Metric | Baseline Actual | Peak Expected | Validation |
|--------|-----------------|---------------|------------|
| **TPS** | 72.6 | 85-90 | [ ] Within expected range |
| **Error Rate** | 0.51% | ~0.5-1% | [ ] Similar or lower |
| **Avg Response Time** | 47ms | 50-60ms | [ ] Slight increase acceptable |
| **P99 Response Time** | 282ms | <400ms | [ ] Within acceptable range |
| **Total Samples** | 130,569 | 155,000-160,000 | [ ] Proportional increase |

**Expected Behavior:**
- ‚úÖ Peak test should achieve ~20% more samples than baseline (108,750 vs 90,612 target)
- ‚úÖ Actual TPS may exceed target by 40-45% (similar to baseline overage)
- ‚úÖ Error rate should stay low (<1%)
- ‚úÖ Response times should stay fast (<100ms average)

---

## 8. Troubleshooting Guide

### Issue 1: FileNotFoundException - JSON File Not Found

**Symptom:**
```
java.io.FileNotFoundException: /Users/.../testdata/holdings_3_411929.json (No such file or directory)
```

**Root Cause:** TESTDATA_DIR path is incorrect or relative

**Resolution:**
1. **Verify file exists:**
   ```bash
   ls -la /Users/samisabir-idrissi/dev/personal/prompt-templates-demo-share/jmeter-prompt-workflow-templates/testdata/holdings_3_411929.json
   ```

2. **Use absolute path in User Defined Variables:**
   - Open test plan in GUI
   - Edit TESTDATA_DIR variable
   - Set to: `/Users/samisabir-idrissi/dev/personal/prompt-templates-demo-share/jmeter-prompt-workflow-templates/testdata`
   - Save and re-run

3. **Verify no typos in __FileToString() calls:**
   - Check each HTTP Request Body Data field
   - Ensure filename matches exactly (case-sensitive)

---

### Issue 2: TPS Much Higher Than Expected (85-90 TPS vs 60.42 Target)

**Symptom:** Test achieves 85-90 TPS instead of 60.42 TPS

**Root Cause:** API response times extremely fast (40-50ms), Constant Throughput Timer can't throttle fast enough

**Analysis:**
- ‚úÖ **This is GOOD NEWS** - indicates system can handle significantly more load
- ‚úÖ Expected behavior based on baseline test (achieved 72.6 vs 50.35 target)
- ‚úÖ Not a test plan error - accurate representation of system capacity

**Action:**
1. **Document actual performance:**
   - Record actual TPS achieved
   - Note that target was exceeded
   - Indicate headroom for growth

2. **If exact 60.42 TPS required:**
   - Consider using Precise Throughput Timer (plugin version)
   - Or reduce thread counts to throttle load

3. **Recommended:** Accept higher TPS as validation that system can handle peak + buffer

---

### Issue 3: Error Rate >1% Under Load

**Symptom:** More than 1% of requests failing

**Debug Steps:**

1. **Check error distribution:**
   - Open "View Results Tree"
   - Filter: ‚òë Errors
   - Examine failure patterns

2. **Common error types:**

   **HTTP 429 (Too Many Requests):**
   - API rate limiting triggered
   - **Solution:** Reduce TPS or increase rate limits

   **HTTP 500 (Internal Server Error):**
   - API crashes or errors
   - **Solution:** Check API logs, investigate root cause

   **HTTP 503 (Service Unavailable):**
   - Insufficient Cloud Function instances
   - **Solution:** Increase max instances in Cloud Run settings

   **Connection Timeout:**
   - Network issues or overloaded server
   - **Solution:** Increase timeout settings, check network latency

3. **Check Google Cloud Console:**
   - Navigate to: Cloud Functions ‚Üí process-portfolio ‚Üí Metrics
   - Review: CPU usage, memory usage, error logs
   - Check: Instance count, throttling events

4. **Gradual load test:**
   - Reduce thread counts by 50%
   - Run test again to isolate capacity limit
   - Increment threads until error rate acceptable

---

### Issue 4: Response Times Exceed SLA (e.g., P95 >300ms for Small-3)

**Symptom:** Duration Assertions failing excessively, samples marked as FAILED

**Root Cause:** API performance degradation under peak load

**Debug Steps:**

1. **Identify affected payload sizes:**
   - Check Aggregate Report: Which thread groups have high response times?
   - Expected: All payloads should have similar fast response times (<100ms)

2. **Check Google Cloud Metrics:**
   - CPU utilization: Is it >80%?
   - Memory utilization: Is it >80%?
   - Cold starts: Are new instances starting frequently?

3. **Performance Analysis:**

   **If CPU >80%:**
   - Increase vCPU allocation in Cloud Run
   - Optimize API code (profiling needed)

   **If Memory >80%:**
   - Increase memory allocation
   - Check for memory leaks

   **If Cold Starts:**
   - Set minimum instances to 1-2
   - Enable CPU always allocated

4. **Temporary Workaround:**
   - Increase Duration Assertion thresholds for testing
   - Document actual P95/P99 response times
   - Re-evaluate SLA targets based on actual performance

---

### Issue 5: Test Stops Prematurely (<30 Minutes)

**Symptom:** Test ends before 1800 seconds complete

**Possible Causes:**

1. **All threads finish iterations early:**
   - **Symptom:** Test completes in 15-20 minutes
   - **Cause:** Loop count set to specific number instead of "Forever"
   - **Solution:** Edit each Thread Group ‚Üí Loop Count: Forever ‚òë

2. **OutOfMemoryError:**
   - **Symptom:** JMeter crashes, log shows `java.lang.OutOfMemoryError`
   - **Solution:** Increase heap size:
     ```bash
     export HEAP="-Xms2g -Xmx4g"
     jmeter -n -t portfolio-peak-test-no-groovy.jmx ...
     ```

3. **Manual stop triggered:**
   - **Symptom:** User clicked Stop button
   - **Solution:** Let test run full 30 minutes uninterrupted

---

### Issue 6: HTML Report Generation Fails

**Symptom:** `.jtl` file created but no HTML report

**Resolution:**

1. **Check output directory:**
   - Error: "Output directory not empty"
   - **Solution:** Delete or rename existing report directory

2. **Verify .jtl file format:**
   - Must be CSV format (not XML)
   - JMeter 5.6+ defaults to CSV, so this should work

3. **Generate report manually:**
   ```bash
   jmeter -g results/peak-results.jtl -o reports/peak-report-manual
   ```

4. **Check for empty .jtl:**
   - If test failed immediately, .jtl may be empty
   - **Solution:** Fix test errors and re-run

---

### Issue 7: __FileToString() Returns Empty Body

**Symptom:** Requests show empty body in "View Results Tree"

**Debug Steps:**

1. **Verify expression syntax:**
   ```
   ${__FileToString(${TESTDATA_DIR}/holdings_3_411929.json,,)}
   ```
   - Check for typos in variable name
   - Ensure three commas total (two empty parameters)

2. **Test variable substitution:**
   - In GUI, add Debug Sampler
   - Check: Does ${TESTDATA_DIR} resolve correctly?
   - Expected: Absolute path to testdata directory

3. **Verify file path:**
   ```bash
   cat /Users/samisabir-idrissi/dev/personal/prompt-templates-demo-share/jmeter-prompt-workflow-templates/testdata/holdings_3_411929.json
   ```
   - Ensure file is readable
   - Check file permissions (755 or 644)

4. **Check JMeter log:**
   ```bash
   tail -f logs/peak-jmeter.log
   ```
   - Look for file reading errors
   - Check for permission denied errors

---

## 9. Comparison with Baseline Test

### 9.1 Configuration Differences

| Aspect | Baseline Test | Peak Test |
|--------|---------------|-----------|
| **Test Plan File** | `portfolio-baseline-test-no-groovy.jmx` | `portfolio-peak-test-no-groovy.jmx` |
| **Total Threads** | 44 | **53** (+9 threads, +20%) |
| **Target TPS** | 50.35 | **60.42** (+10.07 TPS, +20%) |
| **Target RPM** | 3021 | **3625.2** (+604.2 RPM, +20%) |
| **Expected Samples** | 90,612 | **108,756** (+18,144, +20%) |
| **Daily Traffic** | 1,450,000 | **1,740,000** (+290,000, +20%) |

### 9.2 Thread Group Changes

| Thread Group | Baseline | Peak | Œî Threads | Baseline TPS | Peak TPS | Œî TPS |
|--------------|----------|------|-----------|--------------|----------|-------|
| TG-Small-3 | 11 | **14** | +3 | 17.62 | **21.15** | +3.53 |
| TG-Small-10 | 12 | **14** | +2 | 17.62 | **21.15** | +3.53 |
| TG-Medium-67 | 11 | **13** | +2 | 10.07 | **12.08** | +2.01 |
| TG-Large-105 | 5 | **6** | +1 | 3.52 | **4.23** | +0.71 |
| TG-XLarge-245 | 3 | **3** | 0 | 1.01 | **1.21** | +0.20 |
| TG-XXLarge-580 | 2 | **3** | +1 | 0.50 | **0.60** | +0.10 |

### 9.3 What Stayed the Same

‚úÖ **Identical Components:**
- Test duration: 30 minutes
- Ramp-up period: 2 minutes
- Think time: 0.5 seconds
- SLA thresholds: Same per payload size
- JSON files: Same 6 test data files
- Target endpoint: Same Cloud Function
- JSON loading: `__FileToString()` (no Groovy)
- Assertions: HTTP 200 + Duration
- Listeners: View Results Tree + Aggregate Report

---

### 9.4 Expected Performance Comparison

**Based on Baseline Actual Results:**

| Metric | Baseline Target | Baseline Actual | Peak Target | Peak Expected |
|--------|-----------------|-----------------|-------------|---------------|
| **TPS** | 50.35 | **72.6** (+44%) | 60.42 | **~87** (+44%) |
| **Total Samples** | 90,612 | **130,569** (+44%) | 108,756 | **~157,000** (+44%) |
| **Error Rate** | <1% | **0.51%** | <1% | **~0.5-1%** |
| **Avg Response Time** | Varies | **47ms** | Varies | **~50-60ms** |
| **P95 Response Time** | <SLAs | **57ms** | <SLAs | **~60-70ms** |
| **P99 Response Time** | <SLAs | **282ms** | <SLAs | **~300-400ms** |

**Key Insight:** Baseline test already demonstrated capacity to handle peak load. Peak test should achieve similar performance with proportionally higher sample counts.

---

## 10. Next Steps & Future Enhancements

### 10.1 Immediate Next Steps (After Peak Test)

1. **Run Peak Test:**
   ```bash
   jmeter -n -t portfolio-peak-test-no-groovy.jmx \
          -l results/peak-results-$(date +%Y%m%d-%H%M%S).jtl \
          -e -o reports/peak-report-$(date +%Y%m%d-%H%M%S)
   ```

2. **Compare Results with Baseline:**
   - Create comparison spreadsheet
   - Key metrics: TPS, error rate, response times
   - Validate: Peak achieves ~20% more samples than baseline

3. **Document Findings:**
   - Actual TPS achieved (expected: 85-90)
   - Error rate (expected: <1%)
   - Response time distribution
   - Resource utilization (CPU, memory)
   - Capacity headroom identified

4. **Update Capacity Planning:**
   - Document maximum validated load: 85-90 TPS
   - Calculate headroom: (90 - 60.42) / 60.42 = 49% above peak
   - Recommend production scaling limits

---

### 10.2 Optional: Stress Testing

**Purpose:** Find system breaking point beyond peak load

**Approach:** Incrementally increase load until error rate >5%

**Test Plan Creation:**
```bash
# Clone peak test
cp portfolio-peak-test-no-groovy.jmx portfolio-stress-test-no-groovy.jmx

# Modify thread counts:
# - Increase by 50%: 53 ‚Üí 80 threads
# - TPS target: 90 TPS (50% above peak)
# - Monitor for failures

# If successful, try 100 TPS, 150 TPS, etc.
```

**Success Criteria:**
- Identify TPS where error rate >5%
- Document CPU/Memory at failure point
- Establish production safety margin (e.g., 70% of max)

---

### 10.3 CI/CD Integration

**Goal:** Automate peak test execution for regression testing

**Implementation:**

1. **Create Jenkins Pipeline:**
```groovy
pipeline {
    agent any
    stages {
        stage('Run Peak Test') {
            steps {
                sh '''
                    jmeter -n -t portfolio-peak-test-no-groovy.jmx \
                           -l results/peak-${BUILD_NUMBER}.jtl \
                           -e -o reports/peak-${BUILD_NUMBER}
                '''
            }
        }
        stage('Validate Results') {
            steps {
                script {
                    def results = readFile('results/peak-${BUILD_NUMBER}.jtl')
                    // Parse results, check error rate <1%
                    // Fail build if thresholds exceeded
                }
            }
        }
    }
}
```

2. **Schedule Nightly Runs:**
   - Cron: `0 2 * * *` (2 AM daily)
   - Run against staging environment
   - Send results to Slack/email

3. **Performance Regression Detection:**
   - Compare each run to baseline
   - Alert if TPS drops >10% or error rate >1%

---

### 10.4 Enhanced Monitoring

**Backend Listener Integration:**

1. **Add InfluxDB Backend Listener:**
   - Real-time metrics streaming
   - Grafana dashboards
   - Alerting for SLA violations

2. **Google Cloud Monitoring Integration:**
   - Custom metrics: TPS, error rate, response times
   - Dashboards linking JMeter + Cloud metrics
   - Unified view of load test + infrastructure

---

### 10.5 Advanced Test Scenarios

**Multi-Region Testing:**
- Run JMeter from multiple geographic locations
- Validate latency from US, EU, Asia
- Test CDN effectiveness

**Soak Testing:**
- Extend test duration to 2-4 hours
- Identify memory leaks or degradation
- Validate sustained load handling

**Spike Testing:**
- Sudden traffic spike: 0 ‚Üí 100 TPS in 30 seconds
- Validate auto-scaling responsiveness
- Test graceful degradation

---

## 11. References & Documentation

### 11.1 Primary Documentation

1. **Test Plan Specification:**
   - `portfolio-processing-performance-test-plan.md`
   - Section 5.1, Lines 149-159: Peak thread group configurations

2. **Baseline Test Results:**
   - Test Date: 2026-01-13
   - Actual TPS: 72.6 (exceeded 50.35 target by 44%)
   - Error Rate: 0.51%
   - File: Results from baseline test execution

3. **Implementation Plan - Baseline:**
   - `portfolio-baseline-implementation-plan.md`
   - Reference for component configurations

---

### 11.2 Apache JMeter Documentation

1. **Standard Thread Group:**
   - [JMeter Thread Group Documentation](https://jmeter.apache.org/usermanual/component_reference.html#Thread_Group)

2. **Constant Throughput Timer:**
   - [JMeter Constant Throughput Timer](https://jmeter.apache.org/usermanual/component_reference.html#Constant_Throughput_Timer)

3. **__FileToString() Function:**
   - [JMeter Functions Reference](https://jmeter.apache.org/usermanual/functions.html)
   - Syntax: `${__FileToString(file_path,encoding,variable_name)}`

4. **HTTP Request:**
   - [HTTP Request Sampler](https://jmeter.apache.org/usermanual/component_reference.html#HTTP_Request)

5. **Assertions:**
   - [Response Assertion](https://jmeter.apache.org/usermanual/component_reference.html#Response_Assertion)
   - [Duration Assertion](https://jmeter.apache.org/usermanual/component_reference.html#Duration_Assertion)

---

### 11.3 Google Cloud Documentation

1. **Cloud Run Metrics:**
   - [Cloud Run Monitoring](https://cloud.google.com/run/docs/monitoring)

2. **Auto-Scaling:**
   - [Cloud Run Autoscaling](https://cloud.google.com/run/docs/about-instance-autoscaling)

---

### 11.4 Supporting Files

| File | Location | Purpose |
|------|----------|---------|
| `portfolio-peak-test-no-groovy.jmx` | `perf-test-plan/` | Peak test plan |
| `PEAK-TEST-SUMMARY.md` | `perf-test-plan/` | Quick reference guide |
| `BASELINE-VS-PEAK-QUICK-REF.md` | `perf-test-plan/` | Comparison chart |
| `WHICH-VERSION.md` | `perf-test-plan/` | Version selector |
| `CHEATSHEET.md` | `perf-test-plan/` | Command reference |
| `QUICKSTART-JAVA24.md` | `perf-test-plan/` | Java 24 quick start |

---

## 12. Implementation Summary

**Status:** ‚úÖ **Implementation Plan Complete**

**Test Plan:** `portfolio-peak-test-no-groovy.jmx`
**Scenario:** Peak Load (60.42 TPS, 53 threads, 30 minutes)
**Java Compatibility:** 8-24+ (any version)
**Plugins Required:** ‚ùå None

**Key Features:**
- ‚úÖ No Groovy scripts (Java 24+ compatible)
- ‚úÖ `__FileToString()` for JSON loading
- ‚úÖ Standard JMeter components only
- ‚úÖ 53 threads distributed across 6 payload sizes
- ‚úÖ 60.42 TPS target (20% above baseline)
- ‚úÖ Same SLA thresholds as baseline
- ‚úÖ Expected to achieve 85-90 TPS based on baseline results

**Expected Outcome:** Peak test should pass easily, demonstrating system capacity to handle 20% growth with significant headroom remaining.

**Date:** 2026-01-14
**Version:** 1.0
**Status:** Ready for execution

---

**END OF IMPLEMENTATION PLAN**
