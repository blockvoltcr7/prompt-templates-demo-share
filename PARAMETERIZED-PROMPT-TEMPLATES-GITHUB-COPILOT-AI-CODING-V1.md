## **ğŸ¯ PRIORITY 1: TEST AUTOMATION ACCELERATION**

### **Template 4.1: BDD Feature Generation from Test Plan**

```markdown

### **ğŸ”¹ Role:**
You are acting as a **Senior Test Automation Engineer**, responsible for creating comprehensive Cucumber BDD feature files from test plans.

---

### **ğŸ”¹ Context:**
We need to generate a complete BDD feature file for this user story:

**Story**: [PASTE JIRA TITLE HERE]

**Description**:
[PASTE JIRA DESCRIPTION HERE]

**Acceptance Criteria**:
[PASTE ACCEPTANCE CRITERIA HERE]

**Test Plan**:
[PASTE YOUR COMPLETE TEST PLAN HERE]

**Test Data Examples** (Required for Scenario Outlines):
```
[PASTE TEST DATA SETS HERE - Include positive, negative, and boundary data]

Example format:
Valid Login Data:
- username: "validuser@example.com", password: "ValidPass123!", expected: "success"
- username: "admin@company.com", password: "AdminPass456!", expected: "success"

Invalid Login Data:
- username: "invalid@test.com", password: "wrongpass", expected: "Invalid credentials"
- username: "", password: "password", expected: "Username required"
- username: "user@test.com", password: "", expected: "Password required"

Boundary Data:
- username: "a@b.co" (minimum valid), password: "Pass1!", expected: "success"
- username: "very.long.email.address.that.tests.maximum.length@domain.com", password: "LongPass123!", expected: "success"
```

**Swagger/OpenAPI Link** (if applicable):
[PASTE SWAGGER URL OR JSON LINK HERE]

---

### **ğŸ”¹ Your Task:**
Create a complete Cucumber BDD feature file that covers all test scenarios from the test plan using the provided test data.

---

### **ğŸ”¹ Required BDD Structure:**

**Background Section** (optional -- if common setup needed):
- Authentication steps
- Data setup that applies to all scenarios
- Environment configuration

**Scenario vs Scenario Outline Usage**:
- Use **Scenario** for single, specific test cases
- Use **Scenario Outline** with **Examples** table when testing multiple data variations
- Parameterize steps using `<parameter>` syntax for scenario outlines

**Test Data Integration**:
- Map provided test data to Examples tables
- Create separate scenario outlines for different data categories (valid, invalid, boundary)
- Ensure parameter names match between scenario steps and Examples headers

---

### **ğŸ”¹ Required Deliverables:**
- âœ… **Feature Description**: Clear business value statement
- âœ… **Background Section**: Common setup steps if applicable
- âœ… **Individual Scenarios**: Single test cases from test plan
- âœ… **Scenario Outlines**: Parameterized scenarios using provided test data
- âœ… **Examples Tables**: Well-structured data tables matching test data provided
- âœ… **Negative Test Scenarios**: Error cases using invalid test data
- âœ… **Boundary Test Scenarios**: Edge cases using boundary test data
- âœ… **Tags**: Appropriate categorization (@smoke, @regression, @api, @integration, @positive, @negative)

---

### **ğŸ”¹ Test Data Requirements:**
Ensure your scenario outlines properly utilize:
- **Valid test data** for positive scenario outlines
- **Invalid test data** for negative scenario outlines  
- **Boundary test data** for edge case scenario outlines
- **Consistent parameterization** between steps and Examples tables
- **Clear Examples table headers** that match step parameters

---

### **ğŸ”¹ Output Goals:**
Ensure your feature file is:
- ğŸ§© **Test Plan Aligned** covering all scenarios from the provided plan
- ğŸ¯ **Data-Driven** properly utilizing all provided test data examples
- ğŸ” **Maintainable** with reusable step definitions and clear parameterization
- ğŸ“½ï¸ **Framework-ready**: Compatible with Serenity BDD and REST Assured
- ğŸ§ª **Comprehensive** including Background, Scenarios, and Scenario Outlines as appropriate

---

### **ğŸ”¹ BDD Best Practices to Follow:**
- Use descriptive scenario names that explain the test purpose
- Write clear Given-When-Then statements
- Parameterize effectively using `<parameter>` syntax
- Group related test data in logical Examples tables
- Include appropriate tags for test categorization and execution control
- Ensure scenario outlines have meaningful parameter names
- Separate positive and negative scenarios appropriately
```

## **ğŸ¯ Key Enhancements:**

### **1. Explicit Test Data Section**
- **Required field** that forces users to provide test data
- **Clear format examples** showing how to structure data
- **Multiple data categories** (valid, invalid, boundary)

### **2. BDD Structure Guidance**
- **Background usage** explanation a step that always runs for each scenario (optional)
- **Scenario vs Scenario Outline** decision criteria  
- **Parameterization rules** for proper implementation (ensure to parameterize strings and numbers)

### **3. Test Data Integration Requirements**
- **Examples table mapping** to provided data
- **Parameter consistency** between steps and tables
- **Data categorization** for different scenario types

### **4. Enhanced Deliverables**
- **Examples Tables** as explicit deliverable
- **Boundary Test Scenarios** as separate category
- **Parameterization quality** as output goal

```

---

### **Template 4.2: Test Data Generation from Test Plan**

```markdown
### **ğŸ”¹ Role:**
You are acting as a **Test Data Engineer**, responsible for creating comprehensive test datasets based on test plans.

---

### **ğŸ”¹ Context:**
We need test data for this user story:

**Story**: [PASTE JIRA TITLE HERE]
**Description**: [PASTE JIRA DESCRIPTION HERE]
**Acceptance Criteria**: [PASTE ACCEPTANCE CRITERIA HERE]
**Test Plan**: [PASTE YOUR COMPLETE TEST PLAN HERE]

**Data Requirements** (From Test Plan):
[PASTE SPECIFIC DATA NEEDS - e.g., "Need 50 valid users, 20 invalid emails, 10 expired tokens"]

**API Schema/Constraints**:
[PASTE FIELD CONSTRAINTS, DATA FORMATS, VALIDATION RULES HERE]

---

### **ğŸ”¹ Your Task:**
Generate realistic test datasets that support all testing scenarios outlined in the test plan.

---

### **ğŸ”¹ Required Deliverables:**
- âœ… **JSON Test Fixtures**: REST Assured compatible request/response data
- âœ… **Database Seed Data**: SQL scripts for test environment setup  
- âœ… **CSV Data Files**: Bulk data for data-driven testing
- âœ… **Performance Datasets**: Large volumes for load testing
- âœ… **Authentication Data**: Valid/invalid tokens, credentials, sessions

---

### **ğŸ”¹ Output Goals:**
- ğŸ§© **Test Plan Compliant**: Matches exactly what test scenarios need
- ğŸ¯ **Realistic**: Uses believable, production-like data patterns
- ğŸ” **Framework-Ready**: Compatible with REST Assured and test tools
- ğŸ“½ï¸ **Environment-Ready**: Easy to load into test databases/systems

```

---

### **Template 4.3: REST Assured Test Implementation from Test Plan**

```markdown
### **ğŸ”¹ Role:**
You are acting as a **Senior Test Automation Engineer**, responsible for implementing REST Assured test automation code based on test plans.

---

### **ğŸ”¹ Context:**
We need complete REST Assured test implementation for:

**Story**: [PASTE JIRA TITLE HERE]

**Description**:
[PASTE JIRA DESCRIPTION HERE]

**Acceptance Criteria**:
[PASTE ACCEPTANCE CRITERIA HERE]

**Test Plan**:
[PASTE YOUR COMPLETE TEST PLAN HERE]

**Swagger/OpenAPI Link** (if applicable):
[PASTE SWAGGER URL OR JSON LINK HERE]

---

### **ğŸ”¹ Your Task:**
Create complete REST Assured test automation code that implements all test scenarios from the test plan.

---

### **ğŸ”¹ Required Deliverables:**
- âœ… **Step Definition Classes**: Serenity BDD compatible step implementations for all test plan scenarios
- âœ… **Request/Response POJOs**: Data transfer objects based on API specifications
- âœ… **Test Data Builders**: Builder pattern for test data creation per plan requirements
- âœ… **Assertion Helpers**: Reusable validation methods for all test cases
- âœ… **Authentication Setup**: Token management and security handling
- âœ… **Error Handling**: Proper exception management and logging

---

### **ğŸ”¹ Output Goals:**
Ensure your test code is:
- ğŸ§© **Test Plan Driven** implementing every scenario from the plan
- ğŸ¯ **Maintainable** with clear separation of concerns
- ğŸ” **Reusable** across similar test scenarios
- ğŸ“½ï¸ **CI/CD Ready**: Compatible with automated test execution

```

---

## **ğŸ¯ PRIORITY 2: GITHUB COPILOT AGENT MODE**

### **Template 7.1: Workspace Implementation from Plan**

```
### **ğŸ”¹ Role:**
You are acting as a **Senior Solution Architect and Lead Developer**, responsible for implementing features across multiple files in the codebase.

---

### **ğŸ”¹ Context:**
We need to implement this user story across our workspace:

**Story**: [PASTE JIRA TITLE HERE]

**Description**:
[PASTE JIRA DESCRIPTION HERE]

**Acceptance Criteria**:
[PASTE ACCEPTANCE CRITERIA HERE]

**Implementation Plan**:
[PASTE YOUR COMPLETE IMPLEMENTATION PLAN HERE]

**Swagger/OpenAPI Link** (if applicable):
[PASTE SWAGGER URL OR JSON LINK HERE]

---

### **ğŸ”¹ Your Task:**
@workspace Analyze the codebase and implement this feature across all necessary files following the implementation plan.

---

### **ğŸ”¹ Required Analysis Areas:**
- Existing similar implementations in the workspace
- All files requiring modification or creation per plan
- Integration points with existing services
- Test files that need updates
- Documentation requiring changes

---

### **ğŸ”¹ Required Deliverables:**
- âœ… **Implementation Execution**: Follow the provided implementation plan
- âœ… **Code Generation**: New classes, methods, and configurations
- âœ… **Code Modifications**: Updates to existing files per plan
- âœ… **Test Updates**: Unit and integration test changes
- âœ… **Documentation Updates**: README, API docs, comments

---

### **ğŸ”¹ Output Goals:**
Ensure your implementation is:
- ğŸ§© **Plan Compliant** following the provided implementation strategy
- ğŸ¯ **Complete** addressing all acceptance criteria
- ğŸ” **Maintainable** with proper separation of concerns
- ğŸ“½ï¸ **Production-ready**: Includes proper error handling and logging

```

---

### **Template 7.2: Cross-Service Impact Analysis from Plan**

```
### **ğŸ”¹ Role:**
You are acting as a **Senior Solution Architect**, responsible for analyzing the impact of changes across microservices architecture.

---

### **ğŸ”¹ Context:**
We need to understand the cross-service impact of implementing:

**Story**: [PASTE JIRA TITLE HERE]

**Description**:
[PASTE JIRA DESCRIPTION HERE]

**Acceptance Criteria**:
[PASTE ACCEPTANCE CRITERIA HERE]

**Analysis Plan**:
[PASTE YOUR IMPACT ANALYSIS PLAN HERE]

**Swagger/OpenAPI Link** (if applicable):
[PASTE SWAGGER URL OR JSON LINK HERE]

---

### **ğŸ”¹ Your Task:**
@workspace Perform comprehensive impact analysis across all services following the analysis plan.

---

### **ğŸ”¹ Required Analysis Areas:**
- Data flow tracing between services per plan
- API contract compatibility analysis
- Database schema and relationship impacts
- Message queue and event sourcing effects
- External service integration points

---

### **ğŸ”¹ Required Deliverables:**
- âœ… **Plan-Based Assessment**: Follow the provided analysis methodology
- âœ… **Risk Analysis**: Breaking changes and compatibility issues
- âœ… **Change Plan**: Implementation sequence and coordination
- âœ… **Testing Strategy**: Cross-service integration testing approach
- âœ… **Rollback Plan**: Procedures for reverting changes safely

---

### **ğŸ”¹ Output Goals:**
Ensure your analysis is:
- ğŸ§© **Plan Driven** following the provided analysis approach
- ğŸ¯ **Risk-aware** identifying potential failure points
- ğŸ” **Actionable** with clear implementation steps
- ğŸ“½ï¸ **Coordination-ready**: Supporting team collaboration

```

---

## **ğŸ¯ PRIORITY 3: MOB PROGRAMMING WITH AI**

### **Template 6.1: AI Navigator for Mob Programming with Plan**

```
### **ğŸ”¹ Role:**
You are acting as the **Navigator** in a mob programming session, responsible for strategic thinking and guiding implementation decisions.

---

### **ğŸ”¹ Context:**
We are implementing this user story in a mob programming session:

**Story**: [PASTE JIRA TITLE HERE]

**Description**:
[PASTE JIRA DESCRIPTION HERE]

**Acceptance Criteria**:
[PASTE ACCEPTANCE CRITERIA HERE]

**Implementation Plan**:
[PASTE YOUR MOB PROGRAMMING PLAN HERE]

**Current Task**: [DESCRIBE WHAT WE'RE WORKING ON NOW]

**Session Details**:
- Driver: [CURRENT DRIVER NAME]
- Time remaining: [MINUTES LEFT]
- Last completed: [WHAT WAS JUST FINISHED]

---

### **ğŸ”¹ Your Task:**
Guide the mob through implementing this feature following the plan with strategic direction and knowledge sharing.

---

### **ğŸ”¹ Required Navigation Areas:**
- Strategic approach following the implementation plan
- Code quality and best practices guidance
- Knowledge sharing and concept explanation
- Problem-solving when blocked
- Acceptance criteria validation

---

### **ğŸ”¹ Required Deliverables:**
- âœ… **Plan-Based Direction**: Follow implementation plan while providing next steps
- âœ… **Quality Guidance**: Code review and improvement suggestions
- âœ… **Knowledge Transfer**: Explanations and learning opportunities
- âœ… **Progress Tracking**: Alignment with acceptance criteria and plan
- âœ… **Problem Resolution**: Solutions when team gets stuck

---

### **ğŸ”¹ Output Goals:**
Ensure your navigation is:
- ğŸ§© **Plan Aligned** following the provided implementation approach
- ğŸ¯ **Educational** sharing knowledge with the team
- ğŸ” **Collaborative** encouraging team participation
- ğŸ“½ï¸ **Results-oriented**: Driving toward acceptance criteria completion

```

---

## **ğŸ¯ PRIORITY 4: SPRING BOOT SERVICE DEVELOPMENT**

### **Template 3.1: Complete Service Implementation from Plan**

```
### **ğŸ”¹ Role:**
You are acting as a **Senior Spring Boot Developer**, responsible for creating complete, production-ready microservice implementations.

---

### **ğŸ”¹ Context:**
We need a complete Spring Boot implementation for:

**Story**: [PASTE JIRA TITLE HERE]

**Description**:
[PASTE JIRA DESCRIPTION HERE]

**Acceptance Criteria**:
[PASTE ACCEPTANCE CRITERIA HERE]

**Development Plan**:
[PASTE YOUR COMPLETE DEVELOPMENT PLAN HERE]

**Swagger/OpenAPI Link** (if applicable):
[PASTE SWAGGER URL OR JSON LINK HERE]

---

### **ğŸ”¹ Your Task:**
Generate a complete, production-ready Spring Boot implementation following the development plan.

---

### **ğŸ”¹ Required Implementation Areas:**
- Controller layer with REST endpoints per plan
- Service layer with business logic
- Repository/Data access layer
- DTO and entity models
- Security and validation
- Error handling and logging

---

### **ğŸ”¹ Required Deliverables:**
- âœ… **Plan-Based Implementation**: Follow the provided development approach
- âœ… **Service Classes**: Business logic with proper abstractions
- âœ… **Data Layer**: Repository interfaces and implementations
- âœ… **DTOs and Entities**: Request/response and domain models
- âœ… **Configuration**: Security, validation, and application setup
- âœ… **Tests**: Unit and integration test coverage per plan
- âœ… **Documentation**: OpenAPI/Swagger specifications

---

### **ğŸ”¹ Output Goals:**
Ensure your implementation is:
- ğŸ§© **Plan Compliant** following the provided development strategy
- ğŸ¯ **Testable** with comprehensive test coverage
- ğŸ” **Maintainable** following Spring Boot best practices
- ğŸ“½ï¸ **API-complete**: Fully documented with OpenAPI specs

```

Perfect! Now the templates are much more realistic - test automation engineers always create test plans first, then delegate the implementation to AI. The Swagger/OpenAPI link provides the technical API details, while the test plan contains the strategy and scenarios. This is exactly how we work in practice! ğŸš€

# **Why This Template Approach is SIGNIFICANTLY Better**

## **ğŸ¯ REAL-WORLD ALIGNMENT**

### **Mirrors Actual Workflow**

This approach is better because it **matches how teams actually work**. Test automation engineers don't just get a Jira story and start coding - they create test plans first. Developers don't just implement features without implementation plans. This template structure forces the **proper planning phase** that professionals already do, then leverages AI to execute that plan efficiently.

### **Reduces Cognitive Load**

Instead of forcing engineers to break down their requirements into artificial prompt parameters, they can **paste their existing work artifacts** (test plans, implementation plans, acceptance criteria). This eliminates the "translation layer" between how they think and how they prompt AI.

---

## **ğŸ§© SUPERIOR PROMPT ENGINEERING**

### **Structured Role Definition**

The header structure follows **proven prompt engineering principles**:

- **Clear Role Assignment** - AI understands exactly what expertise to apply
- **Explicit Context Setting** - Provides all necessary background information
- **Specific Task Definition** - Eliminates ambiguity about expected outcomes
- **Deliverable Specification** - Creates accountability and completeness
- **Quality Criteria** - Ensures consistent, production-ready outputs

### **Comprehensive Context Provision**

By including complete test plans and implementation strategies, the AI has **full context** rather than fragmented information. This leads to more coherent, realistic, and immediately usable outputs.

---

## **ğŸ” ENTERPRISE SCALABILITY**

### **Template Standardization**

These templates create **organizational consistency**. Every team member uses the same structure, leading to:

- Predictable AI outputs
- Easier knowledge sharing
- Reduced onboarding time for new AI tools
- Standardized quality expectations

### **Plan-Driven Development**

By requiring plans as inputs, these templates **enforce best practices**:

- Forces teams to think through requirements thoroughly
- Creates documentation artifacts for future reference
- Enables better collaboration and review processes
- Reduces "prompt engineering fatigue"

---

## **ğŸ“½ï¸ IMMEDIATE PRACTICAL VALUE**

### **Copy-Paste Simplicity**

Engineers can literally **copy existing documents** into these templates. No need to:

- Learn complex prompt engineering
- Reformat their work into AI-friendly language
- Remember specific parameter structures
- Waste time on prompt iteration

### **Production-Ready Outputs**

Because the templates include comprehensive planning artifacts, the AI generates **complete, enterprise-grade solutions** rather than code snippets that need significant manual enhancement.

---

## **ğŸš€ SUGGESTED IMPROVEMENTS**

### **1. Template Versioning & Evolution**

```
Add version numbers to templates and create improvement cycles:
- Template 4.1.v2: BDD Feature Generation (Updated: 2024-Q4)
- Include "What's New" sections for template updates
- Create feedback loops for template effectiveness

```

### **2. Domain-Specific Template Variants**

```
Create specialized versions for different domains:
- Template 4.1-API: For REST API testing
- Template 4.1-UI: For UI automation testing
- Template 4.1-DB: For database testing
- Template 4.1-Performance: For load testing

```

### **3. Integration with Development Tools**

```
Create IDE snippets and integrations:
- VS Code snippets for quick template access
- Jira integration to auto-populate story details
- Confluence templates that match prompt structures
- Git commit message templates aligned with deliverables

```

### **4. Success Metrics and Validation**

```
Add measurable outcomes to templates:
- Time saved per template usage
- Code quality metrics (coverage, complexity)
- Defect reduction rates
- Team adoption and satisfaction scores

```

### **5. Template Composition and Chaining**

```
Enable template combinations for complex workflows:
- Chain Template 4.1 â†’ 4.2 â†’ 4.3 for complete test automation
- Create "mega-templates" for end-to-end feature development
- Add inter-template dependencies and sequencing

```

### **6. Contextual Template Recommendations**

```
Build intelligence into template selection:
- AI suggests best template based on Jira story type
- Template difficulty ratings (Beginner/Intermediate/Advanced)
- Success rate tracking per template per team
- Automated template optimization based on usage patterns

```

### **7. Quality Assurance Integration**

```
Add quality gates to template outputs:
- Automated code review prompts for generated code
- Security scanning prompts for sensitive operations
- Performance testing prompts for critical paths
- Compliance checking prompts for regulated environments

```

### **8. Knowledge Base Integration**

```
Connect templates to organizational knowledge:
- Auto-populate coding standards from company guidelines
- Include links to relevant architecture decisions
- Reference existing similar implementations in codebase
- Suggest reviewers based on domain expertise

```

This approach transforms AI from a "fancy autocomplete" into a **strategic development partner** that understands and executes professional-grade planning artifacts. It's the difference between giving AI a fishing rod versus teaching it to be a master angler! ğŸ£